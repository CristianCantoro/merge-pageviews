{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-17 17:46:34,195][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-180000.gz\n",
      "[2018-05-17 17:46:36,984][DEBUG]: num_lines: 3673243\n",
      "100% (3673243 of 3673243) |##############| Elapsed Time: 0:00:52 Time:  0:00:52\n",
      "[2018-05-17 17:47:29,542][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 17:47:36,630][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 17:47:36,703][INFO]: Converting pandas DataFrame to Spark DataFrame.\n",
      "[2018-05-17 18:01:10,663][INFO]: Added DataFrame for file sorted_time/2007-12/pagecounts-20071210-180000.gz to list\n",
      "[2018-05-17 18:01:10,730][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-070000.gz\n",
      "[2018-05-17 18:01:12,833][DEBUG]: num_lines: 2685643\n",
      "100% (2685643 of 2685643) |##############| Elapsed Time: 0:00:40 Time:  0:00:40\n",
      "[2018-05-17 18:01:52,881][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 18:01:57,490][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 18:01:57,528][INFO]: Converting pandas DataFrame to Spark DataFrame.\n",
      "[2018-05-17 18:11:47,016][INFO]: Added DataFrame for file sorted_time/2007-12/pagecounts-20071210-070000.gz to list\n",
      "[2018-05-17 18:11:47,061][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-040001.gz\n",
      "[2018-05-17 18:11:49,212][DEBUG]: num_lines: 2888105\n",
      "100% (2888105 of 2888105) |##############| Elapsed Time: 0:00:41 Time:  0:00:41\n",
      "[2018-05-17 18:12:31,162][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 18:12:36,247][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 18:12:36,291][INFO]: Converting pandas DataFrame to Spark DataFrame.\n",
      "[2018-05-17 18:23:18,460][INFO]: Added DataFrame for file sorted_time/2007-12/pagecounts-20071210-040001.gz to list\n",
      "[2018-05-17 18:23:18,507][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-220001.gz\n",
      "[2018-05-17 18:23:21,020][DEBUG]: num_lines: 3422156\n",
      "100% (3422156 of 3422156) |##############| Elapsed Time: 0:00:49 Time:  0:00:49\n",
      "[2018-05-17 18:24:10,736][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 18:24:16,306][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 18:24:16,402][INFO]: Converting pandas DataFrame to Spark DataFrame.\n",
      "[2018-05-17 18:36:50,566][INFO]: Added DataFrame for file sorted_time/2007-12/pagecounts-20071210-220001.gz to list\n",
      "[2018-05-17 18:36:50,611][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-120000.gz\n",
      "[2018-05-17 18:36:53,151][DEBUG]: num_lines: 3409016\n",
      "100% (3409016 of 3409016) |##############| Elapsed Time: 0:00:50 Time:  0:00:50\n",
      "[2018-05-17 18:37:43,606][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 18:37:49,689][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 18:37:49,798][INFO]: Converting pandas DataFrame to Spark DataFrame.\n",
      "[2018-05-17 18:50:50,620][INFO]: Added DataFrame for file sorted_time/2007-12/pagecounts-20071210-120000.gz to list\n",
      "[2018-05-17 18:50:50,675][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-080000.gz\n",
      "[2018-05-17 18:50:52,899][DEBUG]: num_lines: 2936240\n",
      "100% (2936240 of 2936240) |##############| Elapsed Time: 0:00:42 Time:  0:00:42\n",
      "[2018-05-17 18:51:35,159][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 18:51:40,082][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 18:51:40,126][INFO]: Converting pandas DataFrame to Spark DataFrame.\n",
      "[2018-05-17 19:02:26,563][INFO]: Added DataFrame for file sorted_time/2007-12/pagecounts-20071210-080000.gz to list\n",
      "[2018-05-17 19:02:26,600][INFO]: Processing file: sorted_time/2007-12/pagecounts-20071210-030000.gz\n",
      "[2018-05-17 19:02:28,645][DEBUG]: num_lines: 2889569\n",
      "100% (2889569 of 2889569) |##############| Elapsed Time: 0:00:36 Time:  0:00:36\n",
      "[2018-05-17 19:03:04,940][INFO]: Read CSV file into pandas DataFrame.\n",
      "[2018-05-17 19:03:08,987][INFO]: Add timestamp to pandas DataFrame.\n",
      "[2018-05-17 19:03:09,031][INFO]: Converting pandas DataFrame to Spark DataFrame.\n"
     ]
    }
   ],
   "source": [
    "%run -i import_pageviews_spark.py 'sorted_time/2007-12/pagecounts-20071210-*.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['reqbytes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc[(df['lang'] == 'en') & (df['page'] == 'Albert_Camus')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grouped_df = df.groupby(['lang','page', 'day'], as_index=False)\n",
    "# grouped_df = df.groupby(['lang','page', pd.Grouper(freq=\"1D\", key='timestamp')], as_index=False)\n",
    "grouped_df = df.groupby(['lang','page', df.timestamp.dt.day], as_index=False)\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daily_total'] = grouped_df['views'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['views'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['timestamp'].transform(lambda ts: ts.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['lang'] == 'en') & (df['page'] == 'Albert_Camus')].head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
