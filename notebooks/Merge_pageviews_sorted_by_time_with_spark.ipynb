{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gzip\n",
    "import glob\n",
    "import pathlib\n",
    "import argparse\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "########## logging\n",
    "# create logger with 'spam_application'\n",
    "logger = logging.getLogger('notebook')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s]: %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(ch)\n",
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<progressbar.utils.WrappingIO at 0x7f6b345422e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-20 08:07:07,718][DEBUG]: input_files_count: 10\n",
      "[2018-05-20 08:07:07,749][DEBUG]: input_file: ../data/test/pagecounts-20071210-070000.gz\n",
      "[2018-05-20 08:07:07,753][INFO]: Processing file: ../data/test/pagecounts-20071210-070000.gz\n",
      "[2018-05-20 08:07:10,373][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-070000.gz to list\n",
      "[2018-05-20 08:07:10,374][DEBUG]: input_file: ../data/test/pagecounts-20071210-000000.gz\n",
      "[2018-05-20 08:07:10,375][INFO]: Processing file: ../data/test/pagecounts-20071210-000000.gz\n",
      "[2018-05-20 08:07:10,438][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-000000.gz to list\n",
      "[2018-05-20 08:07:10,441][DEBUG]: input_file: ../data/test/pagecounts-20071210-080000.gz\n",
      "[2018-05-20 08:07:10,442][INFO]: Processing file: ../data/test/pagecounts-20071210-080000.gz\n",
      "[2018-05-20 08:07:10,504][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-080000.gz to list\n",
      "[2018-05-20 08:07:10,505][DEBUG]: input_file: ../data/test/pagecounts-20071210-020000.gz\n",
      "[2018-05-20 08:07:10,506][INFO]: Processing file: ../data/test/pagecounts-20071210-020000.gz\n",
      "[2018-05-20 08:07:10,536][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-020000.gz to list\n",
      "[2018-05-20 08:07:10,537][DEBUG]: input_file: ../data/test/pagecounts-20071210-010000.gz\n",
      "[2018-05-20 08:07:10,538][INFO]: Processing file: ../data/test/pagecounts-20071210-010000.gz\n",
      "[2018-05-20 08:07:10,626][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-010000.gz to list\n",
      "[2018-05-20 08:07:10,627][DEBUG]: input_file: ../data/test/pagecounts-20071210-050000.gz\n",
      "[2018-05-20 08:07:10,629][INFO]: Processing file: ../data/test/pagecounts-20071210-050000.gz\n",
      "[2018-05-20 08:07:10,716][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-050000.gz to list\n",
      "[2018-05-20 08:07:10,718][DEBUG]: input_file: ../data/test/pagecounts-20071210-060000.gz\n",
      "[2018-05-20 08:07:10,719][INFO]: Processing file: ../data/test/pagecounts-20071210-060000.gz\n",
      "[2018-05-20 08:07:10,766][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-060000.gz to list\n",
      "[2018-05-20 08:07:10,767][DEBUG]: input_file: ../data/test/pagecounts-20071210-040001.gz\n",
      "[2018-05-20 08:07:10,768][INFO]: Processing file: ../data/test/pagecounts-20071210-040001.gz\n",
      "[2018-05-20 08:07:10,816][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-040001.gz to list\n",
      "[2018-05-20 08:07:10,816][DEBUG]: input_file: ../data/test/pagecounts-20071210-090000.gz\n",
      "[2018-05-20 08:07:10,818][INFO]: Processing file: ../data/test/pagecounts-20071210-090000.gz\n",
      "[2018-05-20 08:07:10,855][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-090000.gz to list\n",
      "[2018-05-20 08:07:10,856][DEBUG]: input_file: ../data/test/pagecounts-20071210-030000.gz\n",
      "[2018-05-20 08:07:10,857][INFO]: Processing file: ../data/test/pagecounts-20071210-030000.gz\n",
      "[2018-05-20 08:07:10,889][INFO]: Added DataFrame for file ../data/test/pagecounts-20071210-030000.gz to list\n",
      "100% (10 of 10) |########################| Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      "[2018-05-20 08:07:10,911][INFO]: Union of all Spark DataFrames.\n",
      "[2018-05-20 08:07:12,944][INFO]: Spark DataFrame created\n",
      "[2018-05-20 08:07:14,472][INFO]: Dropping column \"reqbytes\" from DataFrame\n",
      "[2018-05-20 08:07:14,487][INFO]: Dropped column \"reqbytes\" from DataFrame\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "progressbar.streams.wrap_stderr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, IntegerType, TimestampType\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName=\"merge-pagecounts\")\n",
    "sqlctx = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"lang\", StringType(), False),\n",
    "                     StructField(\"page\", StringType(), False),\n",
    "                     StructField(\"views\", IntegerType(), False),\n",
    "                     StructField(\"reqbytes\", IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionAll(*dfs):\n",
    "    first, *_ = dfs  # Python 3.x, for 2.x you'll have to unpack manually\n",
    "    return first.sql_ctx.createDataFrame(\n",
    "        first.sql_ctx._sc.union([df.rdd for df in dfs]),\n",
    "        first.schema\n",
    "    )\n",
    "\n",
    "\n",
    "def date_parser(timestamp):\n",
    "    return datetime.datetime.strptime(timestamp, '%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfile = \"../data/test/pagecounts-20071210-0*.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files_count = len([f for f in glob.iglob(pathfile)])\n",
    "input_files = glob.iglob(pathfile)\n",
    "\n",
    "# input_files = [\"data/input/sorted_time/2007-12/pagecounts-20071210-000000.gz\",\n",
    "#                \"data/input/sorted_time/2007-12/pagecounts-20071210-010000.gz\"\n",
    "#                ]\n",
    "# input_files_count = len(input_files)\n",
    "\n",
    "logger.debug('input_files_count: {}'.format(input_files_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_files_count < 1:\n",
    "    logger.warn('No input files match: exiting')\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_files_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = list()\n",
    "with progressbar.ProgressBar(max_value=input_files_count) as bar:\n",
    "    for input_file in input_files:\n",
    "        logger.debug('input_file: {}'.format(input_file))\n",
    "\n",
    "        timestamp = date_parser(os.path.basename(input_file)\n",
    "                                       .replace('pagecounts-','')\n",
    "                                       .replace('.gz',''))\n",
    "\n",
    "        logger.info('Processing file: {}'.format(input_file))\n",
    "        tmp_spark_df = sqlctx.read.csv(\n",
    "                            input_file,\n",
    "                            header=False,\n",
    "                            schema=schema,\n",
    "                            sep=' ')\n",
    "\n",
    "        tmp_spark_df = tmp_spark_df.withColumn(\"timestamp\", lit(timestamp))\n",
    "        list_dfs.append(tmp_spark_df)\n",
    "        del tmp_spark_df\n",
    "\n",
    "        logger.info('Added DataFrame for file {} to list'.format(input_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(list_dfs) >= 1, 'There should be at least one DataFrame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(list_dfs) > 1:\n",
    "    logger.info('Union of all Spark DataFrames.')\n",
    "    df = unionAll(*list_dfs)\n",
    "    logger.info('Spark DataFrame created')\n",
    "else:\n",
    "    df = list_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Dropping column \"reqbytes\" from DataFrame')\n",
    "df = df.drop('reqbytes')\n",
    "logger.info('Dropped column \"reqbytes\" from DataFrame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lang', 'string'),\n",
       " ('page', 'string'),\n",
       " ('views', 'int'),\n",
       " ('timestamp', 'timestamp')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_daily_df = (df.select(['lang',\n",
    "                               'page',\n",
    "                               functions.date_format('timestamp','yyyy-MM-dd')\\\n",
    "                                        .alias('day'),\n",
    "                               'views'])\n",
    "                      .groupby(['lang','page','day'])\n",
    "                      .sum('views')\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----------+----------+\n",
      "|lang|                page|       day|sum(views)|\n",
      "+----+--------------------+----------+----------+\n",
      "|  en|Albert_Camus#Furt...|2007-12-10|         1|\n",
      "|  en|Albert_Camuscolum...|2007-12-10|         1|\n",
      "|  en|    Albert_Carnesale|2007-12-10|         9|\n",
      "|  en|        Albert_Camus|2007-12-10|      1362|\n",
      "|  en|      Albert_Bunjaku|2007-12-10|         1|\n",
      "|  en|      Albert_Cadwell|2007-12-10|         1|\n",
      "|  en|       Albert_Caquot|2007-12-10|         4|\n",
      "|  en|     Albert_C._Field|2007-12-10|         1|\n",
      "|  en|Albert_Camus#Oppo...|2007-12-10|         1|\n",
      "|  en|Albert_CamusNon-f...|2007-12-10|         1|\n",
      "+----+--------------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_daily_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = StructType([StructField(\"lang\", StringType(), False),\n",
    "                         StructField(\"page\", StringType(), False),\n",
    "                         StructField(\"day\", StringType(), False),\n",
    "                         StructField(\"enc\", StringType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import pandas as pd\n",
    "\n",
    "hour_to_letter = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O',\n",
    "                  'P','Q','R','S','T','U','V','W','X']\n",
    "\n",
    "@pandas_udf(new_schema, PandasUDFType.GROUPED_MAP)\n",
    "def concat_hours(x):\n",
    "    view_hours = x['hour'].tolist()\n",
    "    view_views = x['views'].tolist()\n",
    "\n",
    "    view_hours_letters = [hour_to_letter[h] for h in view_hours]\n",
    "\n",
    "    encoded_views = [l + str(h)\n",
    "                     for l, h in sorted(zip(view_hours_letters,view_views))]\n",
    "    encoded_views_string = ''.join(encoded_views)\n",
    "\n",
    "    # return pd.DataFrame({'page': x.page, 'lang': x.lang,'day': x.day, 'enc': encoded_views_string}, index=[x.index[0]])\n",
    "    return pd.DataFrame({'enc': x.page, 'day': x.lang, 'lang': x.day, 'page': encoded_views_string}, index=[x.index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions\n",
    "grouped_hours_df = (df.select(['lang',\n",
    "                               'page',\n",
    "                               functions.date_format('timestamp','yyyy-MM-dd').alias('day'), \n",
    "                               functions.hour('timestamp').alias('hour'), \n",
    "                               'views'\n",
    "                               ])\n",
    "                      .groupby(['lang','page','day'])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_hours_df = (grouped_hours_df.apply(concat_hours)\n",
    "                                    .dropDuplicates()\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----------+--------------------+\n",
      "|lang|                page|       day|                 enc|\n",
      "+----+--------------------+----------+--------------------+\n",
      "|  en|        Albert_Cahen|2007-12-10|                  J1|\n",
      "|  en|     Albert_Campbell|2007-12-10|            A1D1F1I1|\n",
      "|  en|Albert_C._L._G._G...|2007-12-10|                  J1|\n",
      "|  en|Albert_Cardinal_V...|2007-12-10|                  E1|\n",
      "|  en|        Albert_Canal|2007-12-10|            A2C1G2I1|\n",
      "|  en|Albert_Camus#Oppo...|2007-12-10|                  E1|\n",
      "|  en|       Albert_Brooks|2007-12-10|                 G16|\n",
      "|  en|      Albert_Cashier|2007-12-10|          A2B1D7E1H2|\n",
      "|  en|     Albert_Castillo|2007-12-10|              B1E1H1|\n",
      "|  en|    Albert_C._Outler|2007-12-10|                  H2|\n",
      "|  en|   Albert_Carotenuto|2007-12-10|                D1H1|\n",
      "|  en|     Albert_C._Field|2007-12-10|                  G1|\n",
      "|  en|Albert_Camus#Summ...|2007-12-10|                  D1|\n",
      "|  en|       Albert_Cavens|2007-12-10|                  A1|\n",
      "|  en|        Albert_Camus|2007-12-10|A150B148C197D173E...|\n",
      "|  en|Albert_CamusNon-f...|2007-12-10|                  I1|\n",
      "|  en|    Albert_Carnesale|2007-12-10|                G4H5|\n",
      "|  en|      Albert_Cadwell|2007-12-10|                  D1|\n",
      "|  en|     Albert_Calmette|2007-12-10|            B1C1F1H1|\n",
      "|  en|       Albert_C_Read|2007-12-10|                  I1|\n",
      "+----+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_hours_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----------+----------+\n",
      "|lang|                page|       day|sum(views)|\n",
      "+----+--------------------+----------+----------+\n",
      "|  en|Albert_Camus#Furt...|2007-12-10|         1|\n",
      "|  en|Albert_Camuscolum...|2007-12-10|         1|\n",
      "|  en|    Albert_Carnesale|2007-12-10|         9|\n",
      "|  en|        Albert_Camus|2007-12-10|      1362|\n",
      "|  en|      Albert_Bunjaku|2007-12-10|         1|\n",
      "|  en|      Albert_Cadwell|2007-12-10|         1|\n",
      "|  en|       Albert_Caquot|2007-12-10|         4|\n",
      "|  en|     Albert_C._Field|2007-12-10|         1|\n",
      "|  en|Albert_Camus#Oppo...|2007-12-10|         1|\n",
      "|  en|Albert_CamusNon-f...|2007-12-10|         1|\n",
      "+----+--------------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_daily_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "daily = grouped_daily_df.select([col('lang').alias('daily_lang'),\n",
    "                                 col('page').alias('daily_page'),\n",
    "                                 col('day').alias('daily_day'),\n",
    "                                 col('sum(views)').alias('daily_sum_views'),                                 \n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+---------------+\n",
      "|daily_lang|          daily_page| daily_day|daily_sum_views|\n",
      "+----------+--------------------+----------+---------------+\n",
      "|        en|Albert_Camus#Furt...|2007-12-10|              1|\n",
      "|        en|Albert_Camuscolum...|2007-12-10|              1|\n",
      "|        en|    Albert_Carnesale|2007-12-10|              9|\n",
      "|        en|        Albert_Camus|2007-12-10|           1362|\n",
      "|        en|      Albert_Bunjaku|2007-12-10|              1|\n",
      "|        en|      Albert_Cadwell|2007-12-10|              1|\n",
      "|        en|       Albert_Caquot|2007-12-10|              4|\n",
      "|        en|     Albert_C._Field|2007-12-10|              1|\n",
      "|        en|Albert_Camus#Oppo...|2007-12-10|              1|\n",
      "|        en|Albert_CamusNon-f...|2007-12-10|              1|\n",
      "|        en|      Albert_Celades|2007-12-10|              6|\n",
      "|        en|      Albert_Cashier|2007-12-10|             13|\n",
      "|        en|      Albert_Calland|2007-12-10|              5|\n",
      "|        en|       Albert_C_Read|2007-12-10|              1|\n",
      "|        en|   Albert_Carotenuto|2007-12-10|              2|\n",
      "|        en|    Albert_C._Greene|2007-12-10|              3|\n",
      "|        en|Albert_Campbell%2...|2007-12-10|              3|\n",
      "|        en| Albert_C._Wedemeyer|2007-12-10|              1|\n",
      "|        en|Albert_Charles_Sa...|2007-12-10|              1|\n",
      "|        en|    Albert_Caravello|2007-12-10|              3|\n",
      "+----------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [daily.daily_lang == grouped_hours_df.lang,\n",
    "        daily.daily_page == grouped_hours_df.page,\n",
    "        daily.daily_day == grouped_hours_df.day]\n",
    "final = daily.join(grouped_hours_df, cond).select(['daily_lang','daily_page','daily_day', 'daily_sum_views', 'enc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+---------------+--------------------+\n",
      "|daily_lang|          daily_page| daily_day|daily_sum_views|                 enc|\n",
      "+----------+--------------------+----------+---------------+--------------------+\n",
      "|        en|Albert_Camus#Furt...|2007-12-10|              1|                  E1|\n",
      "|        en|Albert_Camuscolum...|2007-12-10|              1|                  J1|\n",
      "|        en|    Albert_Carnesale|2007-12-10|              9|                G4H5|\n",
      "|        en|      Albert_Bunjaku|2007-12-10|              1|                  A1|\n",
      "|        en|        Albert_Camus|2007-12-10|           1362|A150B148C197D173E...|\n",
      "|        en|      Albert_Cadwell|2007-12-10|              1|                  D1|\n",
      "|        en|     Albert_C._Field|2007-12-10|              1|                  G1|\n",
      "|        en|Albert_Camus#Oppo...|2007-12-10|              1|                  E1|\n",
      "|        en|       Albert_Caquot|2007-12-10|              4|            C1E1G1I1|\n",
      "|        en|Albert_CamusNon-f...|2007-12-10|              1|                  I1|\n",
      "|        en|      Albert_Celades|2007-12-10|              6|              A3B1J2|\n",
      "|        en|      Albert_Cashier|2007-12-10|             13|          A2B1D7E1H2|\n",
      "|        en|      Albert_Calland|2007-12-10|              5|              B1D3I1|\n",
      "|        en|       Albert_C_Read|2007-12-10|              1|                  I1|\n",
      "|        en|   Albert_Carotenuto|2007-12-10|              2|                D1H1|\n",
      "|        en|    Albert_C._Greene|2007-12-10|              3|              C1D1E1|\n",
      "|        en|Albert_Campbell%2...|2007-12-10|              3|              B1F1I1|\n",
      "|        en| Albert_C._Wedemeyer|2007-12-10|              1|                  B1|\n",
      "|        en|Albert_Charles_Sa...|2007-12-10|              1|                  D1|\n",
      "|        en|    Albert_Caravello|2007-12-10|              3|              C1F1I1|\n",
      "+----------+--------------------+----------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
